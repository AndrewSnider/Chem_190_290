{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "title-cell",
     "locked": false,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Lab 3: Pandas - Useful Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief notes on doing the problems\n",
    "\n",
    "Notebook is designed as a combination walkthrough / problem solving platform. The triple dots (...) represent places in the notebook where you should enter your own code. For question 1a the format of:\n",
    "\n",
    "...\n",
    "<br>\n",
    "best_result_percentage_only\n",
    "\n",
    "indicates that you should replace ... with your code, and have your final output (dataframe, series, array, value, whatever) assigned to the variable name `best_result_percentage_only`\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Make sure your solutions work if you run the notebook from the start (do Kernal > restart and run all)\n",
    "\n",
    "If/when submitting to catcourses, submit PDF version (File > Download as > PDF via LaTeX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "outline-cell",
     "locked": false,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "[Pandas](https://pandas.pydata.org/) is one of the most widely used `Python` libraries in data science. Last week we looked at some basic examples of `Pandas` idexing and dataframe manipulation, here we expand to looking at some useful `Pandas` specific functions:\n",
    "\n",
    "* Aggregating the data (using `.groupby`),\n",
    "* Filtering the data (using boolean arrays and `groupby.filter`),\n",
    "* Pivoting (using `.pivot_table`).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": false,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-189595bbb3fcaa8e",
     "locked": false,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### **REVIEW:** `Groupby` and `Groupby` Shorthand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading in the election dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:15.205576Z",
     "start_time": "2020-09-16T20:55:15.194080Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/elections.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell to load data from CSV file; no further action is needed.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m elections \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/elections.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m elections\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/elections.csv'"
     ]
    }
   ],
   "source": [
    "# Run this cell to load data from CSV file; no further action is needed.\n",
    "elections = pd.read_csv(\"data/elections.csv\")\n",
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw before, we can `groupby` a specific column, e.g., `\"Party\"` and can print out the resulting sub-DataFrames. The output below can help you get an understanding of what `groupby` is actually doing.\n",
    "\n",
    "An example is given below for elections since 1980."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:16.136582Z",
     "start_time": "2020-09-16T20:55:16.020654Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to print sub-DataFrames of a groupby object; no further action is needed.\n",
    "for n, g in elections[elections[\"Year\"] >= 1980].groupby(\"Party\"):\n",
    "    print(f\"Name: {n}\") # By the way, this is an \"f string\", a relatively new and great feature of Python\n",
    "    display(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that once we've formed groups, we can aggregate each sub-DataFrame (a.k.a. group) into a single row using an aggregation function. For example, if we use `.agg('mean')` on the groups above, we get back a single `DataFrame` where each group has been replaced by a single row. In each column for that aggregate row, the value that appears is the average of all values in that group.\n",
    "\n",
    "For columns that are non-numeric, e.g., `\"Result\"`, the `pandas` version we're using (version 2.0.2) will error because we cannot compute the mean of the `Result` column. To remedy this, we add a `numeric_only=True` argument to our function calls so that we only calculate the `mean` for columns that contain numeric values. Alternatively, we can manually select only the numerical columns before calling the `agg` function so the aggregation is only applied to numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections_after_1980 = elections[elections[\"Year\"] >= 1980]\n",
    "\n",
    "elections_after_1980.groupby(\"Party\").agg('mean', numeric_only=True)\n",
    "\n",
    "# alternatively, we can manually select only the numerical columns before calling `agg`\n",
    "# elections_after_1980.groupby(\"Party\")[['Year', 'Popular vote', '%']].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently we can use one of the shorthand aggregation functions, e.g. `.mean()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elections_after_1980.groupby(\"Party\").mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the index of the `DataFrame` returned by an `groupby.agg` call is no longer a set of numeric indices from $0$ to $N-1$. Instead, we see that the index for the example above is now the `Party`. If we want to restore our `DataFrame` so that `Party` is a column rather than the index, we can use `reset_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections_after_1980.groupby(\"Party\").mean(numeric_only=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** Notice that the code above consists of chained method calls. This sort of code is very common in `Pandas` programming and in data science in general. Such chained method calls can sometimes go many layers deep, so you might consider adding newlines between lines of code for clarity. For example, we could instead write the code above as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas method chaining\n",
    "(\n",
    "elections.query(\"Year >= 1980\").groupby(\"Party\") \n",
    "                               .mean(numeric_only=True)  ## Computes the mean values by party\n",
    "                               .reset_index()            ## Resets to a numerical index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have surrounded the entire call by a big set of parentheses so that `Python` doesn't complain about the indentation. An alternative is to use the \\ symbol to indicate to `Python` that your code continues on to the next line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas method chaining (alternative)\n",
    "elections[elections[\"Year\"] >= 1980].groupby(\"Party\") \\\n",
    "                               .mean(numeric_only=True) \\\n",
    "                               .reset_index()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 1a\n",
    "Using `groupby.agg` or one of the shorthand methods (`groupby.min`, `groupby.first`, etc.), create a `Series` object `best_result_percentage_only` that returns a `Series` showing the entire best result for every party, sorted in decreasing order. Your `Series` should include only parties that have earned at least 10% of the vote in some election. Your result should look like this:\n",
    "\n",
    "<code>\n",
    "Party\n",
    "Democratic               61.344703\n",
    "Republican               60.907806\n",
    "Democratic-Republican    57.210122\n",
    "National Union           54.951512\n",
    "Whig                     53.051213\n",
    "Liberal Republican       44.071406\n",
    "National Republican      43.796073\n",
    "Northern Democratic      29.522311\n",
    "Progressive              27.457433\n",
    "American                 21.554001\n",
    "Independent              18.956298\n",
    "Southern Democratic      18.138998\n",
    "American Independent     13.571218\n",
    "Constitutional Union     12.639283\n",
    "Free Soil                10.138474\n",
    "Name: %, dtype: float64\n",
    "</code>\n",
    "<br/>\n",
    "\n",
    "A list of named `groupby.agg` shorthand methods are [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#aggregation) (you'll have to scroll down about one page).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:17.183136Z",
     "start_time": "2020-09-16T20:55:17.172696Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "best_result_percentage_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 1b  \n",
    "Repeat Question 1a. However, this time, your result should be a `DataFrame` showing all available information (all columns) rather than only the percentage as a `Series`.\n",
    "\n",
    "This question is trickier than Question 1a. Make sure to check the lecture slides if you're stuck! It's very easy to make a subtle mistake that shows Woodrow Wilson and Howard Taft both winning the 2020 election.\n",
    "\n",
    "For example, the first 3 rows of your table should be:\n",
    "\n",
    "|Party | Year | Candidate      | Popular Vote | Result | %         |\n",
    "|------|------|----------------|--------------|--------|-----------|\n",
    "|**Democratic**  | 1964 | Lyndon Johnson | 43127041      | win   | 61.344703 |\n",
    "|**Republican**  | 1972 | Richard Nixon | 47168710      | win   | 60.907806 |\n",
    "|**Democratic-Republican**  | 1824 | Andrew Jackson | 151271      | loss   | 57.210122 |\n",
    "\n",
    "Note that the index is `Party`. In other words, don't use `reset_index`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:18.356549Z",
     "start_time": "2020-09-16T20:55:18.350541Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **REVIEW:** `DataFrameGroupBy.filter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `DataFrame` contains a number of parties that have never had a successful presidential run. For example, the 2020 elections included candidates from the Libertarian and Green parties, neither of which have elected a president."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to print the last four rows; no further action is needed.\n",
    "elections.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we were conducting an analysis trying to focus our attention on parties that had elected a president. \n",
    "\n",
    "The most natural approach is to use `groupby.filter` [(docs)](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html). This is an incredibly powerful but subtle tool for filtering data.\n",
    "\n",
    "The code below accomplishes the task at hand. It does this by creating a function that returns `True` if and only if a sub-`DataFrame` (a.k.a. group) contains at least one winner. This function, in turn, uses the `pandas` function `any` [(docs)](https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:19.814724Z",
     "start_time": "2020-09-16T20:55:19.781171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to keep only the rows of parties that have \n",
    "# elected a president; no further action is needed.\n",
    "def at_least_one_candidate_in_the_frame_has_won(frame):\n",
    "    \"\"\"Returns df with rows only kept for parties that have\n",
    "    won at least one election\n",
    "    \"\"\"\n",
    "    return (frame[\"Result\"] == 'win').any()\n",
    "\n",
    "winners_only = (\n",
    "    elections\n",
    "        .groupby(\"Party\")\n",
    "        .filter(at_least_one_candidate_in_the_frame_has_won)\n",
    ")\n",
    "winners_only.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, we could have used a `lambda` function instead of explicitly defining a named function using `def`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to keep only the rows of parties that have \n",
    "# elected a president; no further action is needed.\n",
    "winners_only = (\n",
    "    elections\n",
    "        .groupby(\"Party\")\n",
    "        .filter(lambda x : (x[\"Result\"] == \"win\").any())\n",
    ")\n",
    "winners_only.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 1c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `filter`, create a `DataFrame` object `major_party_results_since_1988` that includes all election results starting after 1988 (exclusive) but only shows a row if the Party it belongs to has earned at least 1% of the popular vote in ANY election since 1988.\n",
    "\n",
    "For example, in 1988, you should not include the `New Alliance` candidate since this party has not earned 1% of the vote since 1988. However, you should include the `Libertarian` candidate from 1988 despite only having 0.47 percent of the vote in 1988, because in 2016 and 2020, the Libertarian candidates Gary Johnson and Jo Jorgensen exceeded 1% of the vote.\n",
    "\n",
    "For example, the first three rows of the table you generate should look like:\n",
    "\n",
    "|     |   Year | Candidate         | Party       |   Popular vote | Result   |         % |\n",
    "|----:|-------:|:------------------|:------------|---------------:|:---------|----------:|\n",
    "| 139 |   1992 | Andre Marrou      | Libertarian |       290087   | loss     | 0.278516  |\n",
    "| 140 |   1992 | Bill Clinton      | Democratic  |       44909806 | win      | 43.118485 |\n",
    "| 142 |   1992 | George H. W. Bush | Republican  |       39104550 | loss     |  37.544784|\n",
    "\n",
    "*Hint*: The following questions might help you construct your solution. One of the lines should be identical to the `filter` examples shown above.\n",
    "\n",
    "1) How can we **only** keep rows in the data starting after 1988 (exclusive)?\n",
    "2) What column should we `groupby` to filter out parties that have earned at least 1% of the popular vote in ANY election since 1988?\n",
    "3) How can we write an aggregation function that takes a sub-DataFrame and returns whether at least 1% of the vote has been earned in that sub-DataFrame? This may give you a hint about the second question!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:21.762599Z",
     "start_time": "2020-09-16T20:55:21.743430Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "major_party_results_since_1988.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **REVIEW:** `str`\n",
    "\n",
    "`Pandas` provides special purpose functions for working with specific common data types such as strings and dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections[\"Candidate\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.str.split`, create a new `DataFrame` called `elections_with_first_name` with a new column `First Name` that is equal to the Candidate's first name.\n",
    "\n",
    "See the `Pandas` `str` [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) for documentation on using `str.split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T03:07:32.775469Z",
     "start_time": "2020-09-16T03:07:32.769402Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "elections_with_first_name = elections.copy()\n",
    "...\n",
    "elections_with_first_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Babynames\n",
    "\n",
    "Looking only at data from CA this time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Mary</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Helen</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Dorothy</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Margaret</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Frances</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State Sex  Year      Name  Count\n",
       "0    CA   F  1910      Mary    295\n",
       "1    CA   F  1910     Helen    239\n",
       "2    CA   F  1910   Dorothy    220\n",
       "3    CA   F  1910  Margaret    163\n",
       "4    CA   F  1910   Frances    134"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os.path\n",
    "import zipfile\n",
    "\n",
    "data_url = \"https://www.ssa.gov/oact/babynames/state/namesbystate.zip\"\n",
    "local_filename = \"data/babynamesbystate.zip\"\n",
    "if not os.path.exists(local_filename): # If the data exists don't download again\n",
    "    with urllib.request.urlopen(data_url) as resp, open(local_filename, 'wb') as f:\n",
    "        f.write(resp.read())\n",
    "\n",
    "zf = zipfile.ZipFile(local_filename, 'r')\n",
    "\n",
    "ca_name = 'STATE.CA.TXT'\n",
    "field_names = ['State', 'Sex', 'Year', 'Name', 'Count']\n",
    "with zf.open(ca_name) as fh:\n",
    "    babynames = pd.read_csv(fh, header=None, names=field_names)\n",
    "\n",
    "babynames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a table with the frequency of all names from 2022. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_18400\\1515817318.py:6: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  .sum()[[\"Count\"]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aadhini</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aadhira</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aadhya</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aadi</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aadit</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>Zyla</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>Zylah</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>Zylo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>Zyon</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>Zyra</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6201 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name  Count\n",
       "0     Aadhini      6\n",
       "1     Aadhira      5\n",
       "2      Aadhya     33\n",
       "3        Aadi     11\n",
       "4       Aadit      5\n",
       "...       ...    ...\n",
       "6196     Zyla     20\n",
       "6197    Zylah     14\n",
       "6198     Zylo      5\n",
       "6199     Zyon     17\n",
       "6200     Zyra     16\n",
       "\n",
       "[6201 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to create a table with the frequency \n",
    "# of all names from 2022; no further action is needed.\n",
    "babynames_2022 = (\n",
    "    babynames[babynames['Year'] == 2022]\n",
    "              .groupby(\"Name\")\n",
    "              .sum()[[\"Count\"]]\n",
    "              .reset_index()\n",
    ")\n",
    "babynames_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `pd.merge` function described in the lecture, combine the `babynames_2022` table with the `elections_with_first_name` table you created earlier to form `presidential_candidates_and_name_popularity`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "presidential_candidates_and_name_popularity = ...\n",
    "presidential_candidates_and_name_popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **REVIEW:** `pandas.pivot_table`\n",
    "\n",
    "The basic concept of a pivot table is taking an existing table / dataframe and 'pivoting' so that the the unique entries in specific columns become the new row indices and column labels. \n",
    "\n",
    "Suppose we want to build a table showing the total number of babies born of each sex in each year. One way is to `groupby` using both columns of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>9163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>9983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>17946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>22094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>26926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>35835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count\n",
       "Year       \n",
       "1910   9163\n",
       "1911   9983\n",
       "1912  17946\n",
       "1913  22094\n",
       "1914  26926\n",
       "1915  35835"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babynames.groupby([\"Year\"])[[\"Count\"]].agg(sum).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this does give us the information we're looking for, a more natural approach is to use pivot tables to represent our data in a more readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>5950</td>\n",
       "      <td>3213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>6602</td>\n",
       "      <td>3381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>9804</td>\n",
       "      <td>8142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>11860</td>\n",
       "      <td>10234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>13815</td>\n",
       "      <td>13111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>18643</td>\n",
       "      <td>17192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count       \n",
       "Sex       F      M\n",
       "Year              \n",
       "1910   5950   3213\n",
       "1911   6602   3381\n",
       "1912   9804   8142\n",
       "1913  11860  10234\n",
       "1914  13815  13111\n",
       "1915  18643  17192"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babynames_pivot = babynames.pivot_table(\n",
    "    index = \"Year\",     # rows (turned into index)\n",
    "    columns = \"Sex\",    # column values\n",
    "    values = [\"Count\"], # field(s) to process in each group\n",
    "    aggfunc = np.sum,   # group operation\n",
    ")\n",
    "babynames_pivot.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also include multiple values in our pivot tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Count</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>295</td>\n",
       "      <td>237</td>\n",
       "      <td>Yvonne</td>\n",
       "      <td>William</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>390</td>\n",
       "      <td>214</td>\n",
       "      <td>Zelma</td>\n",
       "      <td>Willis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>534</td>\n",
       "      <td>501</td>\n",
       "      <td>Yvonne</td>\n",
       "      <td>Woodrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>584</td>\n",
       "      <td>614</td>\n",
       "      <td>Zelma</td>\n",
       "      <td>Yoshio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>773</td>\n",
       "      <td>769</td>\n",
       "      <td>Zelma</td>\n",
       "      <td>Yoshio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>998</td>\n",
       "      <td>1033</td>\n",
       "      <td>Zita</td>\n",
       "      <td>Yukio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Count          Name         \n",
       "Sex      F     M       F        M\n",
       "Year                             \n",
       "1910   295   237  Yvonne  William\n",
       "1911   390   214   Zelma   Willis\n",
       "1912   534   501  Yvonne  Woodrow\n",
       "1913   584   614   Zelma   Yoshio\n",
       "1914   773   769   Zelma   Yoshio\n",
       "1915   998  1033    Zita    Yukio"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babynames_pivot = babynames.pivot_table(\n",
    "    index = \"Year\",     # rows (turned into index)\n",
    "    columns = \"Sex\",    # column values\n",
    "    values = [\"Count\", \"Name\"],\n",
    "    aggfunc = np.max,   # group operation\n",
    ")\n",
    "babynames_pivot.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 4\n",
    "\n",
    "Using `presidential_candidates_and_name_popularity`, create a table, `party_result_popular_vote_pivot`, whose index is the `Party` and whose columns are their `Result`. Each cell should contain the total number of popular votes received. `pandas`' `pivot_table` documentation is [here](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html).\n",
    "\n",
    "You may notice that there are `NaN`s in your table from missing data. Replace the `NaN` values with 0. You may find `.pivot_table`'s `fill_value=` argument helpful. Or, you can use `pd.DataFrame.fillna` [(documentation here)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "party_result_popular_vote_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(best_result_percentage_only)\n15",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> best_result_percentage_only[\"Independent\"].sum()\n18.95629754",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> best_result_percentage_only.iloc[0]\n61.34470329",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> best_result.shape\n(15, 5)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> best_result[\"Popular vote\"].sum() \n135020916",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> best_result.loc[\"Democratic\", \"Candidate\"] \n'Lyndon Johnson'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> major_party_results_since_1988.shape \n(37, 6)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> major_party_results_since_1988[\"%\"].min() \n0.098088334",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> major_party_results_since_1988[\"Candidate\"].iloc[0] \n'Andre Marrou'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> elections_with_first_name.shape\n(182, 7)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> elections_with_first_name[elections_with_first_name[\"Candidate\"] == \"Andrew Jackson\"].iloc[0][\"First Name\"]\n'Andrew'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> elections_with_first_name[elections_with_first_name[\"Candidate\"] == \"Jo Jorgensen\"].iloc[0][\"First Name\"]\n'Jo'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> presidential_candidates_and_name_popularity.shape\n(144, 9)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> presidential_candidates_and_name_popularity[presidential_candidates_and_name_popularity[\"Candidate\"] == \"Andrew Jackson\"].iloc[0][\"Name\"] \n'Andrew'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> presidential_candidates_and_name_popularity[presidential_candidates_and_name_popularity[\"Candidate\"] == \"William Lemke\"].iloc[0][\"Count\"]\n831",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> party_result_popular_vote_pivot.index.name\n'Party'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> \"Result\" in party_result_popular_vote_pivot.columns.names\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # check that there are no NaN values in the DataFrame\n>>> party_result_popular_vote_pivot.isnull().sum().sum() # == 0\n0",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> party_result_popular_vote_pivot.loc['American', 'Popular vote']['loss']\n158271",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> party_result_popular_vote_pivot.loc['American', 'Popular vote']['win']\n0",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> party_result_popular_vote_pivot.loc['Democratic', 'Popular vote']['loss']\n314190254",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> party_result_popular_vote_pivot.loc['Democratic', 'Popular vote']['win']\n441751531",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
